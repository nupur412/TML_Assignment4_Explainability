{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements the [Assignment 4](https://github.com/sprintml/tml_2024/blob/main/Assignment4.pdf) - Task 1 of Trustworthy Machine Learning course offered in the Summer Semester 2024 at the Saarland University. This task focuses obtaining explainations for predictions of last three layers in the Resnet18 models trained on Places 365 and ImageNet datasets using [clip-dissect](https://github.com/Trustworthy-ML-Lab/CLIP-dissect) library and explaining the the predictions made by Resnet 50 model. The report analyzing the results of this task can be accessed [here](https://github.com/nupur412/TML_Assignment4_Explainability/blob/main/TML_Task_1_Report.pdf)"
      ],
      "metadata": {
        "id": "3Oz4ntQbf6Eu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_q2uKNloqEW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from torch.utils.data import DataLoader\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the resnet18 model trained on places 365"
      ],
      "metadata": {
        "id": "0T6no7yAhEPH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg57CCcvPLK_"
      },
      "outputs": [],
      "source": [
        "! wget --progress=bar http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hN3DpqTQnpk"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning the clip dissect library to use it for explainations of the model predictions"
      ],
      "metadata": {
        "id": "Hi0ang0ihQcw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HirHzkvKcQfi"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/Trustworthy-ML-Lab/CLIP-dissect.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the broden dataset which will act as a probing dataset"
      ],
      "metadata": {
        "id": "Rxc-vq9Yhhi0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st8S8DUrBDsh"
      },
      "outputs": [],
      "source": [
        "! bash /content/CLIP-dissect/dlbroden.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before implementing the command in the next sections, we make some changes in the describe neurons file specifically to access the images corresponding to the neurons. The updated describe neurons file can be accessed [here](https://drive.google.com/file/d/1Qhzn1mCPiNsVAMp0avN8g1AmOY_N_ULt/view?usp=drive_link). We leverage the code from [this](https://github.com/Trustworthy-ML-Lab/CLIP-dissect/blob/main/experiments/fig5_use_case.ipynb) experiment from the clip dissect library"
      ],
      "metadata": {
        "id": "KIhTaR4thoQe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIReqZN0R_kQ"
      },
      "outputs": [],
      "source": [
        "! python /content/CLIP-dissect/describe_neurons.py --target_model resnet18_places --target_layers layer3,layer4,fc --d_probe broden --batch_size 200 --device cuda --pool_mode avg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/CLIP-dissect/describe_neurons.py --target_model resnet18 --target_layers layer3,layer4,fc --d_probe broden --concept_set --batch_size 200 --device cuda --pool_mode avg"
      ],
      "metadata": {
        "id": "bN85YakxjWWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation files are generated for each layer after running the above commands and description files are generated that explain which neuron in which layer learns which concept and what is the similarity score"
      ],
      "metadata": {
        "id": "Gk9e_4FDjG6p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70nKU9oNpVVN"
      },
      "outputs": [],
      "source": [
        "activation_files = {\n",
        "    'fc': '/content/CLIP-dissect/saved_activations/broden_resnet18_places_fc.pt',\n",
        "    'layer3': '/content/CLIP-dissect/saved_activations/broden_resnet18_places_layer3.pt',\n",
        "    'layer4': '/content/CLIP-dissect/saved_activations/broden_resnet18_places_layer4.pt'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code blocks are re-executed to obtain results for Resnet 18 trained on ImageNet"
      ],
      "metadata": {
        "id": "Lf9OJwTljg1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4FOPIilk12g",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Load the description file into a DataFrame\n",
        "description_file = '/content/CLIP-dissect/results/resnet18_places/descriptions.csv'\n",
        "df = pd.read_csv(description_file, sep=',', header=0)\n",
        "concepts_places365 = df['description'].tolist()\n",
        "unique_concepts_places365 = set(concepts_places365)\n",
        "num_objects_places365 = len(unique_concepts_places365)\n",
        "\n",
        "if 'description' in df.columns:\n",
        "    concept_counts = df['description'].value_counts()\n",
        "    print(concept_counts)\n",
        "\n",
        "# Count the occurrences of each concept\n",
        "concept_counts = df['description'].value_counts()\n",
        "\n",
        "concept_counts.to_csv('/content/CLIP-dissect/results/resnet18_places/concept_counts.csv', header=['count'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining a plot that shows which are the concepts that a large number of neurons learnt"
      ],
      "metadata": {
        "id": "PWEEC_gkkJ9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG0lpiXjm4Ft"
      },
      "outputs": [],
      "source": [
        "if 'description' in df.columns and 'unit' in df.columns:\n",
        "    top_concepts_per_layer = {}\n",
        "\n",
        "    for layer, activation_file in activation_files.items():\n",
        "        layer_df = df[df['layer'] == layer]\n",
        "\n",
        "        # Count the occurrences of each concept in the current layer\n",
        "        concept_counts = layer_df['description'].value_counts()\n",
        "\n",
        "        # Get the top 20 concepts for the current layer\n",
        "        top_concepts = concept_counts.nlargest(20)\n",
        "        top_concepts_per_layer[layer] = top_concepts\n",
        "\n",
        "        # Save the top concepts to a csv file\n",
        "        output_csv_path = f'/content/CLIP-dissect/results/resnet18_places/concept_counts_{layer}.csv'\n",
        "        top_concepts.to_csv(output_csv_path, header=['count'])\n",
        "\n",
        "        # Plot the top 20 concept counts\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        top_concepts.plot(kind='bar')\n",
        "        plt.title(f'Top 20 Concepts Learned by Most Neurons in {layer}. Total concepts - {len(concept_counts)}')\n",
        "        plt.xlabel('Concepts')\n",
        "        plt.ylabel('Number of Neurons')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        output_image_path = f'/content/CLIP-dissect/results/resnet18_places/concept_counts_plot_{layer}.png'\n",
        "        plt.savefig(output_image_path)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function analyzes the similarity scores"
      ],
      "metadata": {
        "id": "G5ZEUyELj8_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_similarity_scores(description_df, model_name):\n",
        "    similarity_scores = description_df['similarity']\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(similarity_scores, bins=30, kde=True)\n",
        "    plt.title(f'Similarity Scores Distribution in {model_name}')\n",
        "    plt.xlabel('Similarity Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.savefig('/content/CLIP-dissect/results/resnet18_places/similarity_scores.png')\n",
        "    plt.show()\n",
        "\n",
        "analyze_similarity_scores(df, 'ResNet18 (Places365)')"
      ],
      "metadata": {
        "id": "alDKcC9eU5HG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}