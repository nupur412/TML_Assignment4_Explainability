{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements the [Assignment 4](https://github.com/sprintml/tml_2024/blob/main/Assignment4.pdf) - Task 3 of Trustworthy Machine Learning course offered in the Summer Semester 2024 at the Saarland University. This task focuses on obtaining annotations on 10 ImageNet images using [Grad CAM and other methods](https://github.com/jacobgil/pytorch-grad-cam?tab=readme-ov-file#using-from-code-as-a-librarys) technique and explaining the the predictions made by Resnet 50 model. The report analyzing the results of this task can be accessed [here](https://github.com/nupur412/TML_Assignment4_Explainability/blob/main/TML_Task_3_Report.pdf)"
      ],
      "metadata": {
        "id": "piDeMROKpbvf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E_q2uKNloqEW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os, json\n",
        "\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = ['/content/n02098286_West_Highland_white_terrier.JPEG', '/content/n02018207_American_coot.JPEG', '/content/n04037443_racer.JPEG',\n",
        "        '/content/n02007558_flamingo.JPEG', '/content/n01608432_kite.JPEG', '/content/n01443537_goldfish.JPEG',\n",
        "        '/content/n01491361_tiger_shark.JPEG', '/content/n01616318_vulture.JPEG', '/content/n01677366_common_iguana.JPEG',\n",
        "        '/content/n07747607_orange.JPEG']"
      ],
      "metadata": {
        "id": "j6zT_G70EJZL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
      ],
      "metadata": {
        "id": "ezG2IGswEr_G",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer4[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNnn0qb3UnQ7",
        "outputId": "a8cf160b-5cb9-4451-8391-efee579d4773"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bottleneck(\n",
              "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making use of the Grad CAM library for obtaining explainations on the model predictions"
      ],
      "metadata": {
        "id": "6z8Y6haKxZgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/jacobgil/pytorch-grad-cam.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOBQhVMNGw1Q",
        "outputId": "c05c2cc0-2c45-4423-f02a-1b52e5c8e087"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-grad-cam'...\n",
            "remote: Enumerating objects: 1194, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 1194 (delta 56), reused 43 (delta 24), pack-reused 1098\u001b[K\n",
            "Receiving objects: 100% (1194/1194), 133.62 MiB | 14.23 MiB/s, done.\n",
            "Resolving deltas: 100% (668/668), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/pytorch-grad-cam')"
      ],
      "metadata": {
        "id": "pyz0RlY4JvU-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ttach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh-Xfk-8K1r7",
        "outputId": "b53b51a3-cf23-4b4b-b229-5286b8bb25e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "xRm_jemlKmBO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're supposed to compute the gradient of the output with\n",
        "respect to the last convolutional layer, so we modify the target layers accordingly in the cam.py"
      ],
      "metadata": {
        "id": "RMIBPmVIwt2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_layers = [model.layer4[-1]]"
      ],
      "metadata": {
        "id": "xUg2QlBVK_iG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the explainations for each of the 10 ImageNet data points using Grad CAM, Ablation CAM and Score CAM"
      ],
      "metadata": {
        "id": "msOjix-Vxm2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python cam.py --image-path /content/n02098286_West_Highland_white_terrier.JPEG --device cuda --method ablationcam --output-dir /content/pytorch-grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6et2O66IKz58",
        "outputId": "93c77e6f-c145-4e92-8696-6379c8a96779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device \"cuda\" for acceleration\n",
            "100% 64/64 [00:17<00:00,  3.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python cam.py --image-path /content/n01443537_goldfish.JPEG --device cuda --method scorecam --output-dir /content/pytorch-grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaBQEzPacpBI",
        "outputId": "ab2f078b-d07e-4846-f6f0-6ce47a2edb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device \"cuda\" for acceleration\n",
            "100% 64/64 [00:11<00:00,  5.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python cam.py --image-path /content/n07747607_orange.JPEG --device cuda --method gradcam --output-dir /content/pytorch-grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKc36LhYi8jH",
        "outputId": "8726b3db-c492-4a8a-f834-2d96a13cc68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device \"cuda\" for acceleration\n"
          ]
        }
      ]
    }
  ]
}